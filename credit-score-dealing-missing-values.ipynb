{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-02T16:23:37.825989Z","iopub.execute_input":"2022-09-02T16:23:37.826419Z","iopub.status.idle":"2022-09-02T16:23:37.841307Z","shell.execute_reply.started":"2022-09-02T16:23:37.826384Z","shell.execute_reply":"2022-09-02T16:23:37.840360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:37.843620Z","iopub.execute_input":"2022-09-02T16:23:37.844024Z","iopub.status.idle":"2022-09-02T16:23:37.850754Z","shell.execute_reply.started":"2022-09-02T16:23:37.843989Z","shell.execute_reply":"2022-09-02T16:23:37.849515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/credit-score-classification/train.csv\", low_memory = False)\nprint(\"train\", train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:37.852363Z","iopub.execute_input":"2022-09-02T16:23:37.853041Z","iopub.status.idle":"2022-09-02T16:23:38.788873Z","shell.execute_reply.started":"2022-09-02T16:23:37.853000Z","shell.execute_reply":"2022-09-02T16:23:38.787783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data = train)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:38.790267Z","iopub.execute_input":"2022-09-02T16:23:38.791174Z","iopub.status.idle":"2022-09-02T16:23:38.823173Z","shell.execute_reply.started":"2022-09-02T16:23:38.791138Z","shell.execute_reply":"2022-09-02T16:23:38.822064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:38.825953Z","iopub.execute_input":"2022-09-02T16:23:38.826324Z","iopub.status.idle":"2022-09-02T16:23:38.929121Z","shell.execute_reply.started":"2022-09-02T16:23:38.826289Z","shell.execute_reply":"2022-09-02T16:23:38.927906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:38.930494Z","iopub.execute_input":"2022-09-02T16:23:38.930876Z","iopub.status.idle":"2022-09-02T16:23:38.998068Z","shell.execute_reply.started":"2022-09-02T16:23:38.930834Z","shell.execute_reply":"2022-09-02T16:23:38.997017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Realizing Why Data Is Missing\nIt is common to find missing values in data sets both large and small. This issue can lead to significant reduction in the number of usable observations for the analysis. The reduction in the sample size not only reduces statistical power, it can also introduce a bias when the data are not missing at random. ","metadata":{}},{"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)*100/df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:38.999402Z","iopub.execute_input":"2022-09-02T16:23:39.000343Z","iopub.status.idle":"2022-09-02T16:23:39.097875Z","shell.execute_reply.started":"2022-09-02T16:23:39.000306Z","shell.execute_reply":"2022-09-02T16:23:39.096948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We could see in total we have like 60% missing data in the whole data set. Although, there are shared missing values, there are a huge number of missing values in the dataset, moreover we have invalid values too.\n\nThis is the point at which we get into the part of data science that I like to call \"data intution\", by which I mean \"really looking at your data and trying to figure out why it is the way it is and how that will affect your analysis\". It can be a frustrating part of data science, especially if you're newer to the field and don't have a lot of experience. For dealing with missing values, you'll need to use your intution to figure out why the value is missing. One of the most important question you can ask yourself to help figure this out is this:\n\n* **Is the value missing because it wasn't recorded or doesn't exist?**\n\nBy looking at metadata in our dataset, it seems missing values is mainly because of the data collection process considering we have a lot of invalid records in addition to missing values. Thus we could conclude the value in an ideal data set with these features could exist and is not because of not existing the value for the record.\n\nBut let take a closee look to realize whether missing values are related or not.\n","metadata":{}},{"cell_type":"markdown","source":"**Detecting missing values visually using Missingno library:**\n\nMissingno is a simple Python library that presents a series of visualizations to recognize the behavior and distribution of missing data inside a pandas data frame. It can be in the form of a barplot, matrix plot, heatmap, or a dendrogram.","metadata":{}},{"cell_type":"code","source":"import missingno as msno","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:39.099039Z","iopub.execute_input":"2022-09-02T16:23:39.099882Z","iopub.status.idle":"2022-09-02T16:23:39.103943Z","shell.execute_reply.started":"2022-09-02T16:23:39.099846Z","shell.execute_reply":"2022-09-02T16:23:39.102784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(df)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:39.105434Z","iopub.execute_input":"2022-09-02T16:23:39.105824Z","iopub.status.idle":"2022-09-02T16:23:42.223265Z","shell.execute_reply.started":"2022-09-02T16:23:39.105791Z","shell.execute_reply":"2022-09-02T16:23:42.222097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above bar chart give a quick graphical view of all feature. We could see Monthly_inhand_Salary has the most missing value and it could be because of the recording and people don't want to get information of their salaries or not agree to collecting their salary information. We should more dig on the process of collecting data and ask is it collect via a govermental organiation of credit company.\nHowever missing values on **Name** and **Type_of_Loan** is not reasonable. \n\n","metadata":{}},{"cell_type":"markdown","source":"## Matrix \nThe msno.matrix() is a nullity matrix that will help to visualize the location of the null observations.","metadata":{}},{"cell_type":"code","source":"msno.matrix(df.sample(250))","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:42.224928Z","iopub.execute_input":"2022-09-02T16:23:42.225385Z","iopub.status.idle":"2022-09-02T16:23:42.954545Z","shell.execute_reply.started":"2022-09-02T16:23:42.225352Z","shell.execute_reply":"2022-09-02T16:23:42.953668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted = train.sort_values('Monthly_Inhand_Salary')\nmsno.matrix(sorted)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:42.956097Z","iopub.execute_input":"2022-09-02T16:23:42.956456Z","iopub.status.idle":"2022-09-02T16:23:44.975202Z","shell.execute_reply.started":"2022-09-02T16:23:42.956422Z","shell.execute_reply":"2022-09-02T16:23:44.974043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HeatMap\nhe missingno correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another.","metadata":{}},{"cell_type":"code","source":"msno.heatmap(df)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:44.976499Z","iopub.execute_input":"2022-09-02T16:23:44.976882Z","iopub.status.idle":"2022-09-02T16:23:45.625248Z","shell.execute_reply.started":"2022-09-02T16:23:44.976846Z","shell.execute_reply":"2022-09-02T16:23:45.624109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dendrogram\nThe dendrogram allows you to more fully correlate variable completion, revealing trends deeper than the pairwise ones visible in the correlation heatmap:","metadata":{}},{"cell_type":"code","source":"msno.dendrogram(df)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:45.626886Z","iopub.execute_input":"2022-09-02T16:23:45.627604Z","iopub.status.idle":"2022-09-02T16:23:46.337424Z","shell.execute_reply.started":"2022-09-02T16:23:45.627567Z","shell.execute_reply":"2022-09-02T16:23:46.336290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can create a dendrogram showing the clusterings of where data is missing. Leaves that are at the same level predict one another’s presence (empty or filled). The vertical arms are used to indicate how different clusters are.\n\n\nCluster leaves which split close to zero, but not at it, predict one another very well, but still imperfectly. If your own interpretation of the dataset is that these columns actually are or ought to be match each other in nullity, then the height of the cluster leaf tells you, in absolute terms, how often the records are \"mismatched\" or incorrectly filed—that is, how many values you would have to fill in or drop, if you are so inclined.\n\nThus, here we could see base on the levels that **Monthly_Balance** and  **Outstanding_Debt** missing values affect each other. howver, considering the vertical arm between them this effect is not high.","metadata":{}},{"cell_type":"markdown","source":"**Considering the charts, there is not a direct relationship between missing values in column as we expect. Thus, we could move forward and replacing missing values**","metadata":{}},{"cell_type":"markdown","source":"# Filling Missing Values\nFirst we need to drop some of the features and keep the most important ones.","metadata":{}},{"cell_type":"code","source":"df = df.drop(['ID', 'Month', 'Name', 'SSN', 'Interest_Rate','Type_of_Loan', 'Changed_Credit_Limit',\n              'Credit_Mix', 'Credit_Utilization_Ratio', 'Amount_invested_monthly', \n              'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Payment_Behaviour'], axis = 1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:46.341800Z","iopub.execute_input":"2022-09-02T16:23:46.342909Z","iopub.status.idle":"2022-09-02T16:23:46.374504Z","shell.execute_reply.started":"2022-09-02T16:23:46.342866Z","shell.execute_reply":"2022-09-02T16:23:46.373413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)*100/df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:46.375958Z","iopub.execute_input":"2022-09-02T16:23:46.376276Z","iopub.status.idle":"2022-09-02T16:23:46.430418Z","shell.execute_reply.started":"2022-09-02T16:23:46.376247Z","shell.execute_reply":"2022-09-02T16:23:46.429241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Monthly_Inhand_Salary, Credit_History_Age, Num_of_Delayed_payment, Num_Credit_Inquiry and Monthly Balance variables have missing values and espacially **Monthly_Inhand_Salary** and **Credit_History_Age** variable has **24% missing values in total**.","metadata":{}},{"cell_type":"code","source":"sns.displot(data=df['Monthly_Inhand_Salary'], color='teal', kind='kde') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:46.431918Z","iopub.execute_input":"2022-09-02T16:23:46.432926Z","iopub.status.idle":"2022-09-02T16:23:47.169134Z","shell.execute_reply.started":"2022-09-02T16:23:46.432891Z","shell.execute_reply":"2022-09-02T16:23:47.167944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First we need to convert Credir_History_Age to years (From String to Float) then we sketch it to figure out whether we could handle missing values with**","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:17:30.446643Z","iopub.execute_input":"2022-09-02T16:17:30.447804Z","iopub.status.idle":"2022-09-02T16:17:30.455021Z","shell.execute_reply.started":"2022-09-02T16:17:30.447758Z","shell.execute_reply":"2022-09-02T16:17:30.453336Z"}}},{"cell_type":"code","source":"df['Credit_History_Age'] = df['Credit_History_Age'].str[:2]\ndf[['Credit_History_Age']] = df[['Credit_History_Age']].apply(pd.to_numeric)\nsns.displot(data=df['Credit_History_Age'], color='teal', kind='kde') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:23:47.170601Z","iopub.execute_input":"2022-09-02T16:23:47.171784Z","iopub.status.idle":"2022-09-02T16:23:47.936035Z","shell.execute_reply.started":"2022-09-02T16:23:47.171738Z","shell.execute_reply":"2022-09-02T16:23:47.934782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data distribution is almost symmetric, so going to fill it with mean value rather than meadina and mode and compare it with MICE imputing method, which can be better than filling the missing values with median or mean.","metadata":{}},{"cell_type":"code","source":"# Create a function that we can re-use\ndef show_distribution(var_data):\n    from matplotlib import pyplot as plt\n\n    # Get statistics\n    min_val = var_data.min()\n    max_val = var_data.max()\n    mean_val = var_data.mean()\n    med_val = var_data.median()\n    mod_val = var_data.mode()[0]\n\n    print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n                                                                                            mean_val,\n                                                                                            med_val,\n                                                                                            mod_val,\n                                                                                            max_val))\n\n    # Create a figure for 2 subplots (2 rows, 1 column)\n    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n\n    # Plot the histogram   \n    ax[0].hist(var_data)\n    ax[0].set_ylabel('Frequency')\n\n    # Add lines for the mean, median, and mode\n    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n\n    # Plot the boxplot   \n    ax[1].boxplot(var_data, vert=False)\n    ax[1].set_xlabel('Value')\n\n    # Add a title to the Figure\n    fig.suptitle('Data Distribution')\n\n    # Show the figure\n    fig.show()\n\n# Get the variable to examine\ncol = df_students['Grade']\n# Call the function\nshow_distribution(col)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = bike_data['rentals']\n\n\n# Create a figure for 2 subplots (2 rows, 1 column)\nfig, ax = plt.subplots(2, 1, figsize = (9,12))\n\n# Plot the histogram   \nax[0].hist(label, bins=100)\nax[0].set_ylabel('Frequency')\n\n# Add lines for the mean, median, and mode\nax[0].axvline(label.mean(), color='magenta', linestyle='dashed', linewidth=2)\nax[0].axvline(label.median(), color='cyan', linestyle='dashed', linewidth=2)\n\n# Plot the boxplot   \nax[1].boxplot(label, vert=False)\nax[1].set_xlabel('Rentals')\n\n# Add a title to the Figure\nfig.suptitle('Rental Distribution')\n\n# Show the figure\nfig.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}